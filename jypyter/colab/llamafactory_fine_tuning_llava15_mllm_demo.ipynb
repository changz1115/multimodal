{"cells":[{"cell_type":"markdown","metadata":{"id":"t30RA5uglk71"},"source":["# LLaMA-Factory LoRA Fine-Tuning llava1_5\n","https://github.com/hiyouga/LLaMA-Factory/tree/main"]},{"cell_type":"markdown","metadata":{"id":"1H0Hjeailk75"},"source":["## init LLaMA Factory\n","pip部署LLaMA Factory环境(不需要)"]},{"cell_type":"markdown","metadata":{"id":"bVSTm0gNlk76"},"source":["## login huggingface"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXiZlGLQlk76"},"outputs":[],"source":["# from huggingface_hub import HfApi, HfFolder\n","\n","# # 替换为你的 Hugging Face 用户令牌\n","# token = \"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\"\n","\n","# # 保存令牌\n","# HfFolder.save_token(token)\n","\n","# # 创建 HfApi 实例\n","# api = HfApi()\n","\n","# # 验证登录是否成功\n","# user_info = api.whoami()\n","# print(\"Successfully logged in as:\", user_info[\"name\"])\n","\n","HF_TOKEN = \"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\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DffFSWgclk7-","outputId":"6ddc2fde-76c5-48a9-ce7d-c0eafb808b24","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717250845904,"user_tz":-480,"elapsed":126385,"user":{"displayName":"常铮","userId":"09591642841430326743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'LLaMA-Factory'...\n","remote: Enumerating objects: 259, done.\u001b[K\n","remote: Counting objects: 100% (259/259), done.\u001b[K\n","remote: Compressing objects: 100% (217/217), done.\u001b[K\n","remote: Total 259 (delta 46), reused 150 (delta 31), pack-reused 0\u001b[K\n","Receiving objects: 100% (259/259), 7.77 MiB | 14.34 MiB/s, done.\n","Resolving deltas: 100% (46/46), done.\n","/content/LLaMA-Factory\n","Obtaining file:///content/LLaMA-Factory\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (4.41.1)\n","Collecting datasets>=2.14.3 (from llamafactory==0.7.2.dev0)\n","  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate>=0.27.2 (from llamafactory==0.7.2.dev0)\n","  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting peft>=0.10.0 (from llamafactory==0.7.2.dev0)\n","  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trl>=0.8.1 (from llamafactory==0.7.2.dev0)\n","  Downloading trl-0.8.6-py3-none-any.whl (245 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gradio>=4.0.0 (from llamafactory==0.7.2.dev0)\n","  Downloading gradio-4.32.1-py3-none-any.whl (12.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (1.11.4)\n","Collecting einops (from llamafactory==0.7.2.dev0)\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.1.99)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (3.20.3)\n","Collecting uvicorn (from llamafactory==0.7.2.dev0)\n","  Downloading uvicorn-0.30.0-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (2.7.1)\n","Collecting fastapi (from llamafactory==0.7.2.dev0)\n","  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sse-starlette (from llamafactory==0.7.2.dev0)\n","  Downloading sse_starlette-2.1.0-py3-none-any.whl (9.2 kB)\n","Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (3.7.1)\n","Collecting fire (from llamafactory==0.7.2.dev0)\n","  Downloading fire-0.6.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (24.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (6.0.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (3.8.1)\n","Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (0.42.1)\n","Collecting rouge-chinese (from llamafactory==0.7.2.dev0)\n","  Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n","Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.7.2.dev0) (2.3.0+cu121)\n","Collecting bitsandbytes>=0.39.0 (from llamafactory==0.7.2.dev0)\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (1.25.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (5.9.5)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (0.23.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->llamafactory==0.7.2.dev0) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.14.0)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.3->llamafactory==0.7.2.dev0)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (4.66.4)\n","Collecting xxhash (from datasets>=2.14.3->llamafactory==0.7.2.dev0)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets>=2.14.3->llamafactory==0.7.2.dev0)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.9.5)\n","Collecting aiofiles<24.0,>=22.0 (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (4.2.2)\n","Collecting ffmpy (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.17.0 (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading gradio_client-0.17.0-py3-none-any.whl (316 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx>=0.24.1 (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (6.4.0)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.1.5)\n","Collecting orjson~=3.0 (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (9.4.0)\n","Collecting pydub (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart>=0.0.9 (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Collecting ruff>=0.2.2 (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading ruff-0.4.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.0 (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Collecting typer<1.0,>=0.12 (from gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (4.11.0)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.0.7)\n","Collecting websockets<12.0,>=10.0 (from gradio-client==0.17.0->gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.7.2.dev0) (2.8.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.7.2.dev0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.7.2.dev0) (2.18.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.7.2.dev0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.7.2.dev0) (3.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.7.2.dev0) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->llamafactory==0.7.2.dev0)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->llamafactory==0.7.2.dev0) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->llamafactory==0.7.2.dev0) (0.19.1)\n","Collecting tyro>=0.5.11 (from trl>=0.8.1->llamafactory==0.7.2.dev0)\n","  Downloading tyro-0.8.4-py3-none-any.whl (102 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.7.2.dev0) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn->llamafactory==0.7.2.dev0)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette<0.38.0,>=0.37.2 (from fastapi->llamafactory==0.7.2.dev0)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->llamafactory==0.7.2.dev0)\n","  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n","Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->llamafactory==0.7.2.dev0)\n","  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->llamafactory==0.7.2.dev0)\n","  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.7.2.dev0) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.7.2.dev0) (2.4.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->llamafactory==0.7.2.dev0) (1.4.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from sse-starlette->llamafactory==0.7.2.dev0) (3.7.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.12.1)\n","Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->llamafactory==0.7.2.dev0)\n","  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->llamafactory==0.7.2.dev0) (3.7)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.3->llamafactory==0.7.2.dev0) (4.0.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.7.2.dev0) (2024.2.2)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.7.2.dev0) (1.3.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.3->llamafactory==0.7.2.dev0) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.3->llamafactory==0.7.2.dev0) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.14.3->llamafactory==0.7.2.dev0) (3.3.2)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->sse-starlette->llamafactory==0.7.2.dev0) (1.2.1)\n","Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0)\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (13.7.1)\n","Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl>=0.8.1->llamafactory==0.7.2.dev0) (0.16)\n","Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl>=0.8.1->llamafactory==0.7.2.dev0)\n","  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Collecting httptools>=0.5.0 (from uvicorn->llamafactory==0.7.2.dev0)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn->llamafactory==0.7.2.dev0)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn->llamafactory==0.7.2.dev0)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn->llamafactory==0.7.2.dev0)\n","  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->llamafactory==0.7.2.dev0) (1.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.18.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.7.2.dev0) (0.1.2)\n","Building wheels for collected packages: fire, llamafactory, ffmpy\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117029 sha256=bf2a018432762d6c43af4a39dff89ebb1bdf489d8c5d259a63900bc6d41f5fa4\n","  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n","  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llamafactory: filename=llamafactory-0.7.2.dev0-0.editable-py3-none-any.whl size=18708 sha256=51429d1dbe6fc9be196d35678f86e55fe7cccb48bde0de4a07e69b0c66bd66c9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-xkdr6efu/wheels/de/aa/c5/27b5682c5592b7c0eecc3e208f176dedf6b11a61cf2a910b85\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=f856fb78bf7eaa3f772678db66a9bbbef45960f9c001ef3d15c56646ff4df2d2\n","  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n","Successfully built fire llamafactory ffmpy\n","Installing collected packages: pydub, ffmpy, xxhash, websockets, uvloop, ujson, tomlkit, shtab, shellingham, semantic-version, ruff, rouge-chinese, python-multipart, python-dotenv, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, httptools, h11, fire, einops, dnspython, dill, aiofiles, watchfiles, uvicorn, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, httpcore, email_validator, tyro, typer, sse-starlette, nvidia-cusolver-cu12, httpx, gradio-client, fastapi-cli, datasets, fastapi, bitsandbytes, accelerate, trl, peft, gradio, llamafactory\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.9.4\n","    Uninstalling typer-0.9.4:\n","      Successfully uninstalled typer-0.9.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.30.1 aiofiles-23.2.1 bitsandbytes-0.43.1 datasets-2.19.1 dill-0.3.8 dnspython-2.6.1 einops-0.8.0 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 fire-0.6.0 gradio-4.32.1 gradio-client-0.17.0 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 llamafactory-0.7.2.dev0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 orjson-3.10.3 peft-0.11.1 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 rouge-chinese-1.0.3 ruff-0.4.7 semantic-version-2.10.0 shellingham-1.5.4 shtab-1.7.1 sse-starlette-2.1.0 starlette-0.37.2 tomlkit-0.12.0 trl-0.8.6 typer-0.12.3 tyro-0.8.4 ujson-5.10.0 uvicorn-0.30.0 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3 xxhash-3.4.1\n"]}],"source":["!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n","%cd LLaMA-Factory\n","%pip install -e .[torch,metrics,bitsandbytes]"]},{"cell_type":"markdown","metadata":{"id":"g-ZBoMa4lk7-"},"source":["## 确认GPU环境"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xbLZSCZklk7_","outputId":"b1a4d0dd-1617-4e9b-a81e-13a150591897","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717250855857,"user_tz":-480,"elapsed":4040,"user":{"displayName":"常铮","userId":"09591642841430326743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 环境满足\n","Sat Jun  1 14:07:26 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["import torch\n","try:\n","  assert torch.cuda.is_available() is True\n","  print(\"GPU 环境满足\")\n","  !nvidia-smi\n","except AssertionError:\n","  print(\"需要 GPU 环境\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IKO7RsMLlk8A","outputId":"df57f83e-3159-4188-bd87-25e0e9713786","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717251057782,"user_tz":-480,"elapsed":194579,"user":{"displayName":"常铮","userId":"09591642841430326743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-06-01 14:07:44.094816: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-01 14:07:44.094882: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-01 14:07:44.221351: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-06-01 14:07:44.414344: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-01 14:07:45.519648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","06/01/2024 14:07:52 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n","tokenizer_config.json: 100% 1.33k/1.33k [00:00<00:00, 8.48MB/s]\n","tokenizer.model: 100% 500k/500k [00:00<00:00, 13.2MB/s]\n","tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 5.76MB/s]\n","added_tokens.json: 100% 41.0/41.0 [00:00<00:00, 307kB/s]\n","special_tokens_map.json: 100% 438/438 [00:00<00:00, 3.62MB/s]\n","[INFO|tokenization_utils_base.py:2108] 2024-06-01 14:07:54,694 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/tokenizer.model\n","[INFO|tokenization_utils_base.py:2108] 2024-06-01 14:07:54,694 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/tokenizer.json\n","[INFO|tokenization_utils_base.py:2108] 2024-06-01 14:07:54,695 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/added_tokens.json\n","[INFO|tokenization_utils_base.py:2108] 2024-06-01 14:07:54,695 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2108] 2024-06-01 14:07:54,695 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/tokenizer_config.json\n","[WARNING|logging.py:314] 2024-06-01 14:07:54,776 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","preprocessor_config.json: 100% 557/557 [00:00<00:00, 4.01MB/s]\n","[INFO|image_processing_utils.py:374] 2024-06-01 14:07:55,257 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/preprocessor_config.json\n","[INFO|image_processing_utils.py:374] 2024-06-01 14:07:55,337 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/preprocessor_config.json\n","[INFO|image_processing_utils.py:424] 2024-06-01 14:07:55,339 >> Image processor CLIPImageProcessor {\n","  \"_valid_processor_keys\": [\n","    \"images\",\n","    \"do_resize\",\n","    \"size\",\n","    \"resample\",\n","    \"do_center_crop\",\n","    \"crop_size\",\n","    \"do_rescale\",\n","    \"rescale_factor\",\n","    \"do_normalize\",\n","    \"image_mean\",\n","    \"image_std\",\n","    \"do_convert_rgb\",\n","    \"return_tensors\",\n","    \"data_format\",\n","    \"input_data_format\"\n","  ],\n","  \"crop_size\": {\n","    \"height\": 336,\n","    \"width\": 336\n","  },\n","  \"do_center_crop\": true,\n","  \"do_convert_rgb\": true,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.48145466,\n","    0.4578275,\n","    0.40821073\n","  ],\n","  \"image_processor_type\": \"CLIPImageProcessor\",\n","  \"image_std\": [\n","    0.26862954,\n","    0.26130258,\n","    0.27577711\n","  ],\n","  \"processor_class\": \"LlavaProcessor\",\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 336\n","  }\n","}\n","\n","[INFO|tokenization_utils_base.py:2108] 2024-06-01 14:07:55,449 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/tokenizer.model\n","[INFO|tokenization_utils_base.py:2108] 2024-06-01 14:07:55,449 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/tokenizer.json\n","[INFO|tokenization_utils_base.py:2108] 2024-06-01 14:07:55,449 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/added_tokens.json\n","[INFO|tokenization_utils_base.py:2108] 2024-06-01 14:07:55,449 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2108] 2024-06-01 14:07:55,449 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/tokenizer_config.json\n","[WARNING|logging.py:314] 2024-06-01 14:07:55,510 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","[INFO|processing_utils.py:400] 2024-06-01 14:07:55,684 >> Processor LlavaProcessor:\n","- image_processor: CLIPImageProcessor {\n","  \"_valid_processor_keys\": [\n","    \"images\",\n","    \"do_resize\",\n","    \"size\",\n","    \"resample\",\n","    \"do_center_crop\",\n","    \"crop_size\",\n","    \"do_rescale\",\n","    \"rescale_factor\",\n","    \"do_normalize\",\n","    \"image_mean\",\n","    \"image_std\",\n","    \"do_convert_rgb\",\n","    \"return_tensors\",\n","    \"data_format\",\n","    \"input_data_format\"\n","  ],\n","  \"crop_size\": {\n","    \"height\": 336,\n","    \"width\": 336\n","  },\n","  \"do_center_crop\": true,\n","  \"do_convert_rgb\": true,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.48145466,\n","    0.4578275,\n","    0.40821073\n","  ],\n","  \"image_processor_type\": \"CLIPImageProcessor\",\n","  \"image_std\": [\n","    0.26862954,\n","    0.26130258,\n","    0.27577711\n","  ],\n","  \"processor_class\": \"LlavaProcessor\",\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 336\n","  }\n","}\n","\n","- tokenizer: LlamaTokenizerFast(name_or_path='llava-hf/llava-1.5-7b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n","\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32000: AddedToken(\"<image>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32001: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n","\n","{\n","  \"processor_class\": \"LlavaProcessor\"\n","}\n","\n","06/01/2024 14:07:55 - INFO - llamafactory.data.loader - Loading dataset mllm_demo.json...\n","Generating train split: 6 examples [00:00, 307.64 examples/s]\n","num_proc must be <= 6. Reducing num_proc to 6 for dataset of size 6.\n","/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Converting format of dataset (num_proc=6): 100% 6/6 [00:00<00:00, 23.01 examples/s]\n","num_proc must be <= 6. Reducing num_proc to 6 for dataset of size 6.\n","Running tokenizer on dataset (num_proc=6): 100% 6/6 [00:00<00:00,  6.44 examples/s]\n","input_ids:\n","[319, 13563, 1546, 263, 12758, 1404, 322, 385, 23116, 21082, 20255, 29889, 450, 20255, 4076, 8444, 29892, 13173, 29892, 322, 1248, 568, 6089, 304, 278, 1404, 29915, 29879, 5155, 29889, 3148, 1001, 29901, 29871, 32000, 11644, 526, 896, 29973, 319, 1799, 9047, 13566, 29901, 2688, 29915, 276, 476, 1662, 322, 402, 2267, 29920, 1335, 515, 19584, 13564, 436, 29889, 2, 3148, 1001, 29901, 1724, 526, 896, 2599, 29973, 319, 1799, 9047, 13566, 29901, 2688, 526, 10894, 1218, 373, 278, 269, 11953, 1746, 29889, 2]\n","inputs:\n","A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: <image> Who are they? ASSISTANT: They're Kane and Gretzka from Bayern Munich.</s> USER: What are they doing? ASSISTANT: They are celebrating on the soccer field.</s>\n","label_ids:\n","[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2688, 29915, 276, 476, 1662, 322, 402, 2267, 29920, 1335, 515, 19584, 13564, 436, 29889, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2688, 526, 10894, 1218, 373, 278, 269, 11953, 1746, 29889, 2]\n","labels:\n","They're Kane and Gretzka from Bayern Munich.</s> They are celebrating on the soccer field.</s>\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","config.json: 100% 950/950 [00:00<00:00, 6.09MB/s]\n","[INFO|configuration_utils.py:733] 2024-06-01 14:07:57,906 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/config.json\n","/usr/local/lib/python3.10/dist-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect\n","  warnings.warn(\n","[INFO|configuration_utils.py:796] 2024-06-01 14:07:57,918 >> Model config LlavaConfig {\n","  \"_name_or_path\": \"llava-hf/llava-1.5-7b-hf\",\n","  \"architectures\": [\n","    \"LlavaForConditionalGeneration\"\n","  ],\n","  \"ignore_index\": -100,\n","  \"image_token_index\": 32000,\n","  \"model_type\": \"llava\",\n","  \"pad_token_id\": 32001,\n","  \"projector_hidden_act\": \"gelu\",\n","  \"text_config\": {\n","    \"_name_or_path\": \"lmsys/vicuna-7b-v1.5\",\n","    \"architectures\": [\n","      \"LlamaForCausalLM\"\n","    ],\n","    \"max_position_embeddings\": 4096,\n","    \"model_type\": \"llama\",\n","    \"rms_norm_eps\": 1e-05,\n","    \"torch_dtype\": \"float16\",\n","    \"vocab_size\": 32064\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.41.1\",\n","  \"vision_config\": {\n","    \"hidden_size\": 1024,\n","    \"image_size\": 336,\n","    \"intermediate_size\": 4096,\n","    \"model_type\": \"clip_vision_model\",\n","    \"num_attention_heads\": 16,\n","    \"num_hidden_layers\": 24,\n","    \"patch_size\": 14,\n","    \"projection_dim\": 768,\n","    \"vocab_size\": 32000\n","  },\n","  \"vision_feature_layer\": -2,\n","  \"vision_feature_select_strategy\": \"default\"\n","}\n","\n","model.safetensors.index.json: 100% 70.1k/70.1k [00:00<00:00, 1.15MB/s]\n","[INFO|modeling_utils.py:3474] 2024-06-01 14:07:58,356 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/model.safetensors.index.json\n","Downloading shards:   0% 0/3 [00:00<?, ?it/s]\n","model-00001-of-00003.safetensors:   0% 0.00/4.99G [00:00<?, ?B/s]\u001b[A\n","model-00001-of-00003.safetensors:   1% 31.5M/4.99G [00:00<00:19, 250MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   1% 62.9M/4.99G [00:00<00:18, 268MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   2% 94.4M/4.99G [00:00<00:17, 272MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   3% 126M/4.99G [00:00<00:18, 268MB/s] \u001b[A\n","model-00001-of-00003.safetensors:   3% 157M/4.99G [00:00<00:18, 268MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   4% 189M/4.99G [00:00<00:17, 271MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   4% 220M/4.99G [00:00<00:19, 245MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   5% 252M/4.99G [00:00<00:19, 240MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   6% 283M/4.99G [00:01<00:19, 245MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   6% 315M/4.99G [00:01<00:18, 247MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   7% 346M/4.99G [00:01<00:18, 246MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   8% 377M/4.99G [00:01<00:19, 240MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   8% 409M/4.99G [00:01<00:19, 237MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   9% 440M/4.99G [00:01<00:19, 231MB/s]\u001b[A\n","model-00001-of-00003.safetensors:   9% 472M/4.99G [00:01<00:19, 236MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  10% 503M/4.99G [00:02<00:19, 228MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  11% 535M/4.99G [00:02<00:20, 220MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  11% 566M/4.99G [00:02<00:22, 197MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  12% 598M/4.99G [00:02<00:21, 206MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  13% 629M/4.99G [00:02<00:21, 203MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  13% 650M/4.99G [00:02<00:22, 195MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  13% 671M/4.99G [00:02<00:21, 197MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  14% 692M/4.99G [00:03<00:22, 191MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  14% 724M/4.99G [00:03<00:20, 210MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  15% 755M/4.99G [00:03<00:19, 218MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  16% 786M/4.99G [00:03<00:18, 230MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  16% 818M/4.99G [00:03<00:19, 211MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  17% 849M/4.99G [00:03<00:20, 203MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  18% 881M/4.99G [00:03<00:19, 214MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  18% 912M/4.99G [00:05<01:08, 60.0MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  19% 933M/4.99G [00:05<00:57, 70.0MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  19% 965M/4.99G [00:05<00:44, 90.2MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  20% 996M/4.99G [00:05<00:35, 111MB/s] \u001b[A\n","model-00001-of-00003.safetensors:  21% 1.03G/4.99G [00:05<00:29, 135MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  21% 1.06G/4.99G [00:05<00:24, 159MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  22% 1.09G/4.99G [00:06<00:21, 183MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  22% 1.12G/4.99G [00:06<00:19, 195MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  23% 1.15G/4.99G [00:06<00:18, 210MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  24% 1.18G/4.99G [00:06<00:17, 222MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  24% 1.22G/4.99G [00:06<00:16, 228MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  25% 1.25G/4.99G [00:06<00:16, 227MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  26% 1.28G/4.99G [00:06<00:15, 239MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  26% 1.31G/4.99G [00:06<00:14, 246MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  27% 1.34G/4.99G [00:07<00:14, 251MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  28% 1.37G/4.99G [00:07<00:14, 247MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  28% 1.41G/4.99G [00:07<00:14, 245MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  29% 1.44G/4.99G [00:07<00:14, 248MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  29% 1.47G/4.99G [00:07<00:13, 252MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  30% 1.50G/4.99G [00:07<00:13, 253MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  31% 1.53G/4.99G [00:07<00:13, 262MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  31% 1.56G/4.99G [00:07<00:13, 257MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  32% 1.59G/4.99G [00:08<00:13, 259MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  33% 1.63G/4.99G [00:08<00:13, 245MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  33% 1.66G/4.99G [00:08<00:13, 242MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  34% 1.69G/4.99G [00:08<00:13, 244MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  34% 1.72G/4.99G [00:08<00:13, 248MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  35% 1.75G/4.99G [00:08<00:12, 252MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  36% 1.78G/4.99G [00:08<00:12, 253MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  36% 1.81G/4.99G [00:08<00:12, 250MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  37% 1.85G/4.99G [00:09<00:12, 248MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  38% 1.88G/4.99G [00:09<00:12, 250MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  38% 1.91G/4.99G [00:09<00:12, 242MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  39% 1.94G/4.99G [00:09<00:12, 248MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  39% 1.97G/4.99G [00:09<00:12, 248MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  40% 2.00G/4.99G [00:09<00:11, 250MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  41% 2.03G/4.99G [00:09<00:12, 242MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  41% 2.07G/4.99G [00:09<00:11, 248MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  42% 2.10G/4.99G [00:10<00:11, 251MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  43% 2.13G/4.99G [00:10<00:12, 236MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  43% 2.16G/4.99G [00:10<00:12, 221MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  44% 2.19G/4.99G [00:10<00:12, 228MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  45% 2.22G/4.99G [00:10<00:12, 226MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  45% 2.25G/4.99G [00:10<00:11, 233MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  46% 2.29G/4.99G [00:10<00:11, 236MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  46% 2.32G/4.99G [00:11<00:11, 240MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  47% 2.35G/4.99G [00:11<00:11, 231MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  48% 2.38G/4.99G [00:11<00:11, 237MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  48% 2.41G/4.99G [00:11<00:10, 238MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  49% 2.44G/4.99G [00:11<00:10, 240MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  50% 2.47G/4.99G [00:11<00:10, 244MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  50% 2.51G/4.99G [00:11<00:10, 247MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  51% 2.54G/4.99G [00:11<00:09, 248MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  51% 2.57G/4.99G [00:12<00:09, 247MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  52% 2.60G/4.99G [00:12<00:09, 246MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  53% 2.63G/4.99G [00:12<00:09, 247MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  53% 2.66G/4.99G [00:12<00:09, 239MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  54% 2.69G/4.99G [00:12<00:09, 238MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  55% 2.73G/4.99G [00:12<00:09, 246MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  55% 2.76G/4.99G [00:12<00:08, 252MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  56% 2.79G/4.99G [00:12<00:08, 249MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  56% 2.82G/4.99G [00:13<00:08, 248MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  57% 2.85G/4.99G [00:13<00:08, 250MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  58% 2.88G/4.99G [00:13<00:08, 249MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  58% 2.92G/4.99G [00:13<00:08, 253MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  59% 2.95G/4.99G [00:13<00:08, 250MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  60% 2.98G/4.99G [00:13<00:07, 253MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  60% 3.01G/4.99G [00:13<00:08, 237MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  61% 3.04G/4.99G [00:14<00:08, 234MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  62% 3.07G/4.99G [00:14<00:08, 236MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  62% 3.10G/4.99G [00:14<00:08, 234MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  63% 3.14G/4.99G [00:14<00:07, 234MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  63% 3.17G/4.99G [00:14<00:08, 218MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  64% 3.20G/4.99G [00:14<00:08, 209MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  65% 3.23G/4.99G [00:14<00:08, 209MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  65% 3.26G/4.99G [00:15<00:08, 209MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  66% 3.29G/4.99G [00:15<00:07, 220MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  67% 3.32G/4.99G [00:15<00:07, 227MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  67% 3.36G/4.99G [00:15<00:07, 216MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  68% 3.39G/4.99G [00:15<00:07, 207MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  68% 3.42G/4.99G [00:15<00:07, 202MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  69% 3.44G/4.99G [00:15<00:07, 200MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  69% 3.46G/4.99G [00:16<00:07, 197MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  70% 3.48G/4.99G [00:18<00:42, 35.4MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  70% 3.50G/4.99G [00:18<00:45, 33.1MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  71% 3.53G/4.99G [00:18<00:29, 48.8MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  71% 3.57G/4.99G [00:19<00:21, 67.9MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  72% 3.60G/4.99G [00:19<00:15, 90.0MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  73% 3.63G/4.99G [00:19<00:12, 110MB/s] \u001b[A\n","model-00001-of-00003.safetensors:  73% 3.66G/4.99G [00:19<00:10, 132MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  74% 3.69G/4.99G [00:19<00:08, 153MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  75% 3.72G/4.99G [00:19<00:07, 168MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  75% 3.75G/4.99G [00:19<00:06, 183MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  76% 3.79G/4.99G [00:19<00:05, 203MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  76% 3.82G/4.99G [00:20<00:05, 222MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  77% 3.85G/4.99G [00:20<00:04, 235MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  78% 3.88G/4.99G [00:20<00:04, 243MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  78% 3.91G/4.99G [00:20<00:04, 246MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  79% 3.94G/4.99G [00:21<00:17, 58.6MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  79% 3.96G/4.99G [00:22<00:15, 68.0MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  80% 3.98G/4.99G [00:22<00:12, 78.8MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  80% 4.01G/4.99G [00:23<00:24, 41.0MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  81% 4.03G/4.99G [00:23<00:19, 50.6MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  81% 4.05G/4.99G [00:23<00:14, 63.8MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  81% 4.07G/4.99G [00:23<00:11, 79.3MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  82% 4.10G/4.99G [00:23<00:08, 108MB/s] \u001b[A\n","model-00001-of-00003.safetensors:  83% 4.13G/4.99G [00:25<00:18, 46.8MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  83% 4.15G/4.99G [00:25<00:14, 56.2MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  84% 4.17G/4.99G [00:25<00:12, 67.6MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  84% 4.19G/4.99G [00:25<00:09, 80.8MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  85% 4.23G/4.99G [00:25<00:07, 105MB/s] \u001b[A\n","model-00001-of-00003.safetensors:  85% 4.26G/4.99G [00:25<00:05, 132MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  86% 4.29G/4.99G [00:26<00:04, 155MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  87% 4.32G/4.99G [00:26<00:03, 173MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  87% 4.35G/4.99G [00:26<00:03, 193MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  88% 4.38G/4.99G [00:26<00:02, 208MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  88% 4.41G/4.99G [00:26<00:02, 222MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  89% 4.45G/4.99G [00:26<00:02, 227MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  90% 4.48G/4.99G [00:26<00:02, 229MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  90% 4.51G/4.99G [00:26<00:02, 236MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  91% 4.54G/4.99G [00:27<00:01, 244MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  92% 4.57G/4.99G [00:27<00:01, 240MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  92% 4.60G/4.99G [00:27<00:01, 232MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  93% 4.63G/4.99G [00:27<00:01, 237MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  93% 4.67G/4.99G [00:27<00:01, 211MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  94% 4.70G/4.99G [00:27<00:01, 202MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  95% 4.72G/4.99G [00:27<00:01, 198MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  95% 4.74G/4.99G [00:28<00:01, 193MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  95% 4.76G/4.99G [00:28<00:01, 194MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  96% 4.78G/4.99G [00:28<00:01, 132MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  96% 4.80G/4.99G [00:28<00:01, 139MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  97% 4.82G/4.99G [00:28<00:01, 148MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  97% 4.84G/4.99G [00:28<00:00, 156MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  97% 4.87G/4.99G [00:28<00:00, 160MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  98% 4.89G/4.99G [00:29<00:00, 166MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  98% 4.91G/4.99G [00:29<00:00, 173MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  99% 4.93G/4.99G [00:29<00:00, 174MB/s]\u001b[A\n","model-00001-of-00003.safetensors:  99% 4.95G/4.99G [00:29<00:00, 181MB/s]\u001b[A\n","model-00001-of-00003.safetensors: 100% 4.97G/4.99G [00:29<00:00, 183MB/s]\u001b[A\n","model-00001-of-00003.safetensors: 100% 4.99G/4.99G [00:29<00:00, 168MB/s]\n","Downloading shards:  33% 1/3 [00:29<00:59, 29.83s/it]\n","model-00002-of-00003.safetensors:   0% 0.00/4.96G [00:00<?, ?B/s]\u001b[A\n","model-00002-of-00003.safetensors:   1% 31.5M/4.96G [00:00<00:22, 219MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   1% 62.9M/4.96G [00:00<00:23, 207MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   2% 83.9M/4.96G [00:00<00:24, 203MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   2% 115M/4.96G [00:00<00:22, 211MB/s] \u001b[A\n","model-00002-of-00003.safetensors:   3% 147M/4.96G [00:00<00:21, 220MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   4% 178M/4.96G [00:00<00:21, 227MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   4% 210M/4.96G [00:00<00:20, 233MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   5% 241M/4.96G [00:01<00:20, 234MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   5% 273M/4.96G [00:01<00:20, 233MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   6% 304M/4.96G [00:01<00:19, 242MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   7% 336M/4.96G [00:01<00:18, 253MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   7% 367M/4.96G [00:01<00:17, 260MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   8% 398M/4.96G [00:01<00:18, 249MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   9% 430M/4.96G [00:01<00:18, 240MB/s]\u001b[A\n","model-00002-of-00003.safetensors:   9% 461M/4.96G [00:01<00:18, 246MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  10% 493M/4.96G [00:02<00:18, 245MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  11% 524M/4.96G [00:02<00:17, 251MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  11% 556M/4.96G [00:02<00:17, 253MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  12% 587M/4.96G [00:02<00:17, 249MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  12% 619M/4.96G [00:02<00:17, 248MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  13% 650M/4.96G [00:02<00:17, 252MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  14% 682M/4.96G [00:02<00:16, 255MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  14% 713M/4.96G [00:02<00:16, 257MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  15% 744M/4.96G [00:03<00:17, 247MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  16% 776M/4.96G [00:03<00:17, 245MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  16% 807M/4.96G [00:03<00:16, 247MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  17% 839M/4.96G [00:03<00:16, 245MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  18% 870M/4.96G [00:03<00:16, 246MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  18% 902M/4.96G [00:03<00:16, 253MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  19% 933M/4.96G [00:04<00:23, 168MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  19% 965M/4.96G [00:04<00:20, 192MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  20% 996M/4.96G [00:04<00:19, 208MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  21% 1.03G/4.96G [00:04<00:18, 208MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  21% 1.06G/4.96G [00:04<00:18, 213MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  22% 1.09G/4.96G [00:04<00:17, 219MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  23% 1.12G/4.96G [00:04<00:17, 221MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  23% 1.15G/4.96G [00:04<00:16, 229MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  24% 1.18G/4.96G [00:05<00:16, 232MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  25% 1.22G/4.96G [00:05<00:16, 230MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  25% 1.25G/4.96G [00:05<00:15, 234MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  26% 1.28G/4.96G [00:05<00:15, 238MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  26% 1.31G/4.96G [00:05<00:15, 238MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  27% 1.34G/4.96G [00:05<00:15, 238MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  28% 1.37G/4.96G [00:05<00:15, 237MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  28% 1.41G/4.96G [00:06<00:14, 242MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  29% 1.44G/4.96G [00:06<00:14, 246MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  30% 1.47G/4.96G [00:06<00:14, 244MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  30% 1.50G/4.96G [00:06<00:14, 247MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  31% 1.53G/4.96G [00:06<00:13, 250MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  32% 1.56G/4.96G [00:06<00:13, 250MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  32% 1.59G/4.96G [00:06<00:13, 249MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  33% 1.63G/4.96G [00:06<00:13, 247MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  33% 1.66G/4.96G [00:07<00:12, 254MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  34% 1.69G/4.96G [00:07<00:13, 251MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  35% 1.72G/4.96G [00:07<00:12, 252MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  35% 1.75G/4.96G [00:07<00:13, 242MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  36% 1.78G/4.96G [00:07<00:13, 241MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  37% 1.81G/4.96G [00:07<00:13, 240MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  37% 1.85G/4.96G [00:07<00:12, 240MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  38% 1.88G/4.96G [00:07<00:12, 246MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  38% 1.91G/4.96G [00:08<00:12, 249MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  39% 1.94G/4.96G [00:08<00:11, 257MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  40% 1.97G/4.96G [00:08<00:12, 235MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  40% 2.00G/4.96G [00:08<00:12, 244MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  41% 2.03G/4.96G [00:08<00:11, 250MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  42% 2.07G/4.96G [00:08<00:11, 256MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  42% 2.10G/4.96G [00:08<00:11, 246MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  43% 2.13G/4.96G [00:08<00:11, 240MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  44% 2.16G/4.96G [00:09<00:11, 241MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  44% 2.19G/4.96G [00:09<00:11, 243MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  45% 2.22G/4.96G [00:09<00:11, 245MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  45% 2.25G/4.96G [00:09<00:11, 245MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  46% 2.29G/4.96G [00:09<00:10, 243MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  47% 2.32G/4.96G [00:09<00:10, 242MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  47% 2.35G/4.96G [00:09<00:10, 238MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  48% 2.38G/4.96G [00:09<00:10, 238MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  49% 2.41G/4.96G [00:10<00:10, 242MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  49% 2.44G/4.96G [00:10<00:10, 239MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  50% 2.47G/4.96G [00:10<00:10, 236MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  51% 2.51G/4.96G [00:10<00:10, 232MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  51% 2.54G/4.96G [00:10<00:10, 236MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  52% 2.57G/4.96G [00:10<00:10, 232MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  52% 2.60G/4.96G [00:10<00:11, 214MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  53% 2.63G/4.96G [00:11<00:11, 198MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  54% 2.66G/4.96G [00:11<00:11, 202MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  54% 2.68G/4.96G [00:11<00:11, 202MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  55% 2.71G/4.96G [00:11<00:11, 201MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  55% 2.74G/4.96G [00:11<00:11, 196MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  56% 2.76G/4.96G [00:11<00:11, 193MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  56% 2.78G/4.96G [00:11<00:12, 178MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  56% 2.80G/4.96G [00:12<00:12, 167MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  57% 2.82G/4.96G [00:12<00:12, 172MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  57% 2.84G/4.96G [00:12<00:12, 174MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  58% 2.86G/4.96G [00:15<01:47, 19.5MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  58% 2.89G/4.96G [00:15<01:08, 30.3MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  59% 2.93G/4.96G [00:15<00:46, 44.1MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  60% 2.96G/4.96G [00:16<00:32, 61.3MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  60% 2.99G/4.96G [00:16<00:24, 80.8MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  61% 3.02G/4.96G [00:16<00:19, 99.4MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  62% 3.05G/4.96G [00:16<00:15, 121MB/s] \u001b[A\n","model-00002-of-00003.safetensors:  62% 3.08G/4.96G [00:16<00:13, 140MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  63% 3.11G/4.96G [00:16<00:11, 158MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  63% 3.15G/4.96G [00:16<00:10, 178MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  64% 3.18G/4.96G [00:17<00:09, 188MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  65% 3.21G/4.96G [00:17<00:08, 202MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  65% 3.24G/4.96G [00:17<00:08, 212MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  66% 3.27G/4.96G [00:17<00:07, 222MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  67% 3.30G/4.96G [00:17<00:07, 225MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  67% 3.33G/4.96G [00:17<00:07, 231MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  68% 3.37G/4.96G [00:17<00:06, 231MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  69% 3.40G/4.96G [00:17<00:06, 230MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  69% 3.43G/4.96G [00:18<00:06, 238MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  70% 3.46G/4.96G [00:18<00:06, 241MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  70% 3.49G/4.96G [00:18<00:06, 240MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  71% 3.52G/4.96G [00:18<00:05, 243MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  72% 3.55G/4.96G [00:18<00:05, 244MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  72% 3.59G/4.96G [00:18<00:05, 248MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  73% 3.62G/4.96G [00:18<00:05, 256MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  74% 3.65G/4.96G [00:18<00:05, 257MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  74% 3.68G/4.96G [00:19<00:05, 250MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  75% 3.71G/4.96G [00:19<00:06, 182MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  75% 3.73G/4.96G [00:19<00:07, 160MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  76% 3.75G/4.96G [00:19<00:07, 155MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  76% 3.77G/4.96G [00:19<00:07, 162MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  77% 3.80G/4.96G [00:19<00:06, 169MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  77% 3.83G/4.96G [00:20<00:05, 189MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  78% 3.85G/4.96G [00:20<00:05, 190MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  78% 3.88G/4.96G [00:20<00:05, 203MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  79% 3.91G/4.96G [00:20<00:05, 198MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  79% 3.93G/4.96G [00:20<00:05, 181MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  80% 3.95G/4.96G [00:20<00:06, 149MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  80% 3.97G/4.96G [00:21<00:06, 147MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  81% 4.00G/4.96G [00:21<00:06, 154MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  81% 4.03G/4.96G [00:21<00:05, 174MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  82% 4.06G/4.96G [00:21<00:04, 192MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  82% 4.09G/4.96G [00:21<00:04, 208MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  83% 4.12G/4.96G [00:21<00:04, 199MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  84% 4.14G/4.96G [00:23<00:22, 37.0MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  84% 4.17G/4.96G [00:23<00:15, 51.6MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  85% 4.20G/4.96G [00:24<00:10, 69.3MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  85% 4.24G/4.96G [00:24<00:08, 88.3MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  86% 4.26G/4.96G [00:24<00:07, 96.3MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  86% 4.28G/4.96G [00:24<00:06, 108MB/s] \u001b[A\n","model-00002-of-00003.safetensors:  87% 4.30G/4.96G [00:24<00:05, 124MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  87% 4.32G/4.96G [00:24<00:04, 138MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  88% 4.35G/4.96G [00:24<00:03, 153MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  88% 4.37G/4.96G [00:25<00:04, 120MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  89% 4.39G/4.96G [00:25<00:04, 132MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  89% 4.41G/4.96G [00:25<00:03, 141MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  89% 4.44G/4.96G [00:25<00:03, 153MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  90% 4.46G/4.96G [00:25<00:03, 162MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  90% 4.48G/4.96G [00:25<00:02, 172MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  91% 4.51G/4.96G [00:25<00:02, 191MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  92% 4.54G/4.96G [00:25<00:02, 203MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  92% 4.56G/4.96G [00:26<00:01, 201MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  93% 4.59G/4.96G [00:26<00:01, 213MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  93% 4.62G/4.96G [00:26<00:01, 221MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  94% 4.66G/4.96G [00:26<00:01, 226MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  95% 4.69G/4.96G [00:26<00:01, 230MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  95% 4.72G/4.96G [00:26<00:01, 230MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  96% 4.75G/4.96G [00:26<00:00, 223MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  96% 4.78G/4.96G [00:26<00:00, 230MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  97% 4.81G/4.96G [00:27<00:00, 230MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  98% 4.84G/4.96G [00:27<00:00, 234MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  98% 4.88G/4.96G [00:27<00:00, 238MB/s]\u001b[A\n","model-00002-of-00003.safetensors:  99% 4.91G/4.96G [00:27<00:00, 238MB/s]\u001b[A\n","model-00002-of-00003.safetensors: 100% 4.96G/4.96G [00:27<00:00, 179MB/s]\n","Downloading shards:  67% 2/3 [00:57<00:28, 28.71s/it]\n","model-00003-of-00003.safetensors:   0% 0.00/4.18G [00:00<?, ?B/s]\u001b[A\n","model-00003-of-00003.safetensors:   1% 31.5M/4.18G [00:00<00:14, 290MB/s]\u001b[A\n","model-00003-of-00003.safetensors:   2% 62.9M/4.18G [00:00<00:14, 276MB/s]\u001b[A\n","model-00003-of-00003.safetensors:   2% 94.4M/4.18G [00:00<00:14, 275MB/s]\u001b[A\n","model-00003-of-00003.safetensors:   3% 126M/4.18G [00:00<00:15, 263MB/s] \u001b[A\n","model-00003-of-00003.safetensors:   4% 157M/4.18G [00:00<00:16, 237MB/s]\u001b[A\n","model-00003-of-00003.safetensors:   5% 189M/4.18G [00:00<00:16, 238MB/s]\u001b[A\n","model-00003-of-00003.safetensors:   5% 220M/4.18G [00:00<00:16, 238MB/s]\u001b[A\n","model-00003-of-00003.safetensors:   6% 252M/4.18G [00:01<00:16, 233MB/s]\u001b[A\n","model-00003-of-00003.safetensors:   7% 283M/4.18G [00:01<00:16, 234MB/s]\u001b[A\n","model-00003-of-00003.safetensors:   8% 315M/4.18G [00:01<00:16, 235MB/s]\u001b[A\n","model-00003-of-00003.safetensors:   8% 346M/4.18G [00:01<00:16, 236MB/s]\u001b[A\n","model-00003-of-00003.safetensors:   9% 377M/4.18G [00:01<00:16, 232MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  10% 409M/4.18G [00:01<00:16, 232MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  11% 440M/4.18G [00:01<00:15, 237MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  11% 472M/4.18G [00:01<00:15, 241MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  12% 503M/4.18G [00:02<00:15, 237MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  13% 535M/4.18G [00:02<00:15, 237MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  14% 566M/4.18G [00:02<00:15, 233MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  14% 598M/4.18G [00:02<00:15, 237MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  15% 629M/4.18G [00:02<00:14, 241MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  16% 661M/4.18G [00:02<00:14, 242MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  17% 692M/4.18G [00:02<00:14, 247MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  17% 724M/4.18G [00:02<00:14, 246MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  18% 755M/4.18G [00:03<00:13, 254MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  19% 786M/4.18G [00:03<00:13, 253MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  20% 818M/4.18G [00:03<00:13, 253MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  20% 849M/4.18G [00:03<00:13, 249MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  21% 881M/4.18G [00:03<00:12, 255MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  22% 912M/4.18G [00:03<00:12, 252MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  23% 944M/4.18G [00:03<00:12, 254MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  23% 975M/4.18G [00:03<00:12, 254MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  24% 1.01G/4.18G [00:04<00:12, 261MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  25% 1.04G/4.18G [00:04<00:12, 252MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  26% 1.07G/4.18G [00:04<00:12, 253MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  26% 1.10G/4.18G [00:04<00:12, 249MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  27% 1.13G/4.18G [00:04<00:12, 248MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  28% 1.16G/4.18G [00:04<00:12, 248MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  29% 1.20G/4.18G [00:04<00:12, 247MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  29% 1.23G/4.18G [00:04<00:11, 246MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  30% 1.26G/4.18G [00:05<00:11, 249MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  31% 1.29G/4.18G [00:05<00:12, 236MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  32% 1.32G/4.18G [00:05<00:11, 238MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  32% 1.35G/4.18G [00:05<00:11, 246MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  33% 1.38G/4.18G [00:05<00:11, 244MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  34% 1.42G/4.18G [00:05<00:10, 251MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  35% 1.45G/4.18G [00:05<00:11, 237MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  35% 1.48G/4.18G [00:06<00:11, 234MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  36% 1.51G/4.18G [00:06<00:11, 226MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  37% 1.54G/4.18G [00:06<00:11, 226MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  38% 1.57G/4.18G [00:06<00:11, 223MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  38% 1.60G/4.18G [00:06<00:11, 231MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  39% 1.64G/4.18G [00:06<00:11, 230MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  40% 1.67G/4.18G [00:06<00:10, 232MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  41% 1.70G/4.18G [00:07<00:10, 238MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  41% 1.73G/4.18G [00:07<00:10, 238MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  42% 1.76G/4.18G [00:07<00:10, 237MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  43% 1.79G/4.18G [00:07<00:10, 238MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  44% 1.82G/4.18G [00:07<00:09, 242MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  44% 1.86G/4.18G [00:07<00:09, 239MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  45% 1.89G/4.18G [00:07<00:09, 233MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  46% 1.92G/4.18G [00:07<00:09, 235MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  47% 1.95G/4.18G [00:08<00:09, 234MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  47% 1.98G/4.18G [00:08<00:09, 227MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  48% 2.01G/4.18G [00:08<00:09, 219MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  49% 2.04G/4.18G [00:08<00:10, 204MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  49% 2.07G/4.18G [00:08<00:10, 201MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  50% 2.10G/4.18G [00:08<00:10, 199MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  51% 2.13G/4.18G [00:09<00:14, 146MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  52% 2.16G/4.18G [00:09<00:12, 166MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  52% 2.19G/4.18G [00:09<00:10, 181MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  53% 2.21G/4.18G [00:09<00:10, 184MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  53% 2.23G/4.18G [00:09<00:10, 182MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  54% 2.25G/4.18G [00:09<00:10, 189MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  54% 2.28G/4.18G [00:09<00:09, 192MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  55% 2.30G/4.18G [00:09<00:09, 193MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  55% 2.32G/4.18G [00:12<01:02, 29.7MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  56% 2.35G/4.18G [00:12<00:41, 44.4MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  57% 2.38G/4.18G [00:12<00:28, 62.1MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  58% 2.41G/4.18G [00:12<00:21, 81.9MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  59% 2.44G/4.18G [00:12<00:16, 103MB/s] \u001b[A\n","model-00003-of-00003.safetensors:  59% 2.47G/4.18G [00:12<00:13, 124MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  60% 2.51G/4.18G [00:13<00:11, 144MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  61% 2.54G/4.18G [00:13<00:10, 160MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  62% 2.57G/4.18G [00:13<00:09, 174MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  62% 2.60G/4.18G [00:13<00:08, 186MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  63% 2.63G/4.18G [00:13<00:07, 199MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  64% 2.66G/4.18G [00:13<00:07, 209MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  65% 2.69G/4.18G [00:13<00:06, 216MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  65% 2.73G/4.18G [00:13<00:06, 225MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  66% 2.76G/4.18G [00:14<00:06, 228MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  67% 2.79G/4.18G [00:14<00:06, 229MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  68% 2.82G/4.18G [00:14<00:06, 224MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  68% 2.85G/4.18G [00:14<00:05, 229MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  69% 2.88G/4.18G [00:14<00:05, 228MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  70% 2.92G/4.18G [00:14<00:05, 233MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  71% 2.95G/4.18G [00:14<00:05, 232MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  71% 2.98G/4.18G [00:15<00:05, 230MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  72% 3.01G/4.18G [00:15<00:04, 234MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  73% 3.04G/4.18G [00:15<00:04, 237MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  74% 3.07G/4.18G [00:15<00:04, 240MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  74% 3.10G/4.18G [00:15<00:04, 234MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  75% 3.14G/4.18G [00:15<00:04, 238MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  76% 3.17G/4.18G [00:15<00:04, 241MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  77% 3.20G/4.18G [00:15<00:04, 241MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  77% 3.23G/4.18G [00:16<00:03, 244MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  78% 3.26G/4.18G [00:16<00:03, 243MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  79% 3.29G/4.18G [00:16<00:03, 247MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  80% 3.32G/4.18G [00:16<00:03, 247MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  80% 3.36G/4.18G [00:16<00:03, 238MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  81% 3.39G/4.18G [00:16<00:03, 241MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  82% 3.42G/4.18G [00:16<00:03, 243MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  83% 3.45G/4.18G [00:17<00:02, 244MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  83% 3.48G/4.18G [00:17<00:02, 243MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  84% 3.51G/4.18G [00:17<00:02, 249MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  85% 3.54G/4.18G [00:17<00:02, 248MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  86% 3.58G/4.18G [00:17<00:02, 249MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  86% 3.61G/4.18G [00:17<00:02, 252MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  87% 3.64G/4.18G [00:17<00:02, 246MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  88% 3.67G/4.18G [00:17<00:02, 245MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  89% 3.70G/4.18G [00:18<00:01, 254MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  89% 3.73G/4.18G [00:18<00:01, 258MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  90% 3.76G/4.18G [00:18<00:01, 246MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  91% 3.80G/4.18G [00:18<00:01, 248MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  92% 3.83G/4.18G [00:18<00:01, 252MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  92% 3.86G/4.18G [00:18<00:01, 251MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  93% 3.89G/4.18G [00:18<00:01, 254MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  94% 3.92G/4.18G [00:18<00:01, 245MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  95% 3.95G/4.18G [00:19<00:00, 243MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  95% 3.98G/4.18G [00:19<00:00, 252MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  96% 4.02G/4.18G [00:19<00:00, 172MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  97% 4.04G/4.18G [00:19<00:00, 179MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  97% 4.07G/4.18G [00:19<00:00, 188MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  98% 4.10G/4.18G [00:19<00:00, 200MB/s]\u001b[A\n","model-00003-of-00003.safetensors:  99% 4.13G/4.18G [00:19<00:00, 210MB/s]\u001b[A\n","model-00003-of-00003.safetensors: 100% 4.18G/4.18G [00:20<00:00, 207MB/s]\n","Downloading shards: 100% 3/3 [01:18<00:00, 26.05s/it]\n","[INFO|modeling_utils.py:1519] 2024-06-01 14:09:16,494 >> Instantiating LlavaForConditionalGeneration model under default dtype torch.float16.\n","[INFO|configuration_utils.py:962] 2024-06-01 14:09:16,496 >> Generate config GenerationConfig {\n","  \"pad_token_id\": 32001\n","}\n","\n","[INFO|configuration_utils.py:962] 2024-06-01 14:09:16,987 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2\n","}\n","\n","Loading checkpoint shards: 100% 3/3 [01:01<00:00, 20.41s/it]\n","[INFO|modeling_utils.py:4280] 2024-06-01 14:10:18,582 >> All model checkpoint weights were used when initializing LlavaForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4288] 2024-06-01 14:10:18,582 >> All the weights of LlavaForConditionalGeneration were initialized from the model checkpoint at llava-hf/llava-1.5-7b-hf.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use LlavaForConditionalGeneration for predictions without further training.\n","generation_config.json: 100% 141/141 [00:00<00:00, 779kB/s]\n","[INFO|configuration_utils.py:917] 2024-06-01 14:10:18,756 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/generation_config.json\n","[INFO|configuration_utils.py:962] 2024-06-01 14:10:18,756 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2,\n","  \"pad_token_id\": 32001\n","}\n","\n","06/01/2024 14:10:18 - INFO - llamafactory.model.utils.checkpointing - Gradient checkpointing enabled.\n","06/01/2024 14:10:18 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n","06/01/2024 14:10:18 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n","06/01/2024 14:10:18 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n","06/01/2024 14:10:19 - INFO - llamafactory.model.loader - trainable params: 4194304 || all params: 7067621376 || trainable%: 0.0593\n","[INFO|trainer.py:641] 2024-06-01 14:10:19,792 >> Using auto half precision backend\n","[INFO|trainer.py:2078] 2024-06-01 14:10:20,182 >> ***** Running training *****\n","[INFO|trainer.py:2079] 2024-06-01 14:10:20,182 >>   Num examples = 5\n","[INFO|trainer.py:2080] 2024-06-01 14:10:20,182 >>   Num Epochs = 3\n","[INFO|trainer.py:2081] 2024-06-01 14:10:20,182 >>   Instantaneous batch size per device = 1\n","[INFO|trainer.py:2084] 2024-06-01 14:10:20,182 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2085] 2024-06-01 14:10:20,182 >>   Gradient Accumulation steps = 8\n","[INFO|trainer.py:2086] 2024-06-01 14:10:20,182 >>   Total optimization steps = 3\n","[INFO|trainer.py:2087] 2024-06-01 14:10:20,185 >>   Number of trainable parameters = 4,194,304\n","  0% 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","[WARNING|logging.py:329] 2024-06-01 14:10:22,730 >> `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n","100% 3/3 [00:22<00:00,  6.48s/it][INFO|trainer.py:2329] 2024-06-01 14:10:42,703 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 22.5177, 'train_samples_per_second': 0.666, 'train_steps_per_second': 0.133, 'train_loss': 0.7742036183675131, 'epoch': 2.0}\n","100% 3/3 [00:22<00:00,  7.50s/it]\n","[INFO|trainer.py:3410] 2024-06-01 14:10:42,706 >> Saving model checkpoint to saves/llava1_5-7b/lora/sft\n","/usr/local/lib/python3.10/dist-packages/transformers/models/llava/configuration_llava.py:140: FutureWarning: The `vocab_size` attribute is deprecated and will be removed in v4.42, Please use `text_config.vocab_size` instead.\n","  warnings.warn(\n","[INFO|configuration_utils.py:733] 2024-06-01 14:10:42,905 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--llava-hf--llava-1.5-7b-hf/snapshots/05ae2434cbb430be33edcba0c5203e7023f785b7/config.json\n","[INFO|configuration_utils.py:796] 2024-06-01 14:10:42,908 >> Model config LlavaConfig {\n","  \"architectures\": [\n","    \"LlavaForConditionalGeneration\"\n","  ],\n","  \"ignore_index\": -100,\n","  \"image_token_index\": 32000,\n","  \"model_type\": \"llava\",\n","  \"pad_token_id\": 32001,\n","  \"projector_hidden_act\": \"gelu\",\n","  \"text_config\": {\n","    \"_name_or_path\": \"lmsys/vicuna-7b-v1.5\",\n","    \"architectures\": [\n","      \"LlamaForCausalLM\"\n","    ],\n","    \"max_position_embeddings\": 4096,\n","    \"model_type\": \"llama\",\n","    \"rms_norm_eps\": 1e-05,\n","    \"torch_dtype\": \"float16\",\n","    \"vocab_size\": 32064\n","  },\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.41.1\",\n","  \"vision_config\": {\n","    \"hidden_size\": 1024,\n","    \"image_size\": 336,\n","    \"intermediate_size\": 4096,\n","    \"model_type\": \"clip_vision_model\",\n","    \"num_attention_heads\": 16,\n","    \"num_hidden_layers\": 24,\n","    \"patch_size\": 14,\n","    \"projection_dim\": 768,\n","    \"vocab_size\": 32000\n","  },\n","  \"vision_feature_layer\": -2,\n","  \"vision_feature_select_strategy\": \"default\"\n","}\n","\n","[INFO|tokenization_utils_base.py:2513] 2024-06-01 14:10:42,980 >> tokenizer config file saved in saves/llava1_5-7b/lora/sft/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2522] 2024-06-01 14:10:42,981 >> Special tokens file saved in saves/llava1_5-7b/lora/sft/special_tokens_map.json\n","[INFO|image_processing_utils.py:257] 2024-06-01 14:10:43,045 >> Image processor saved in saves/llava1_5-7b/lora/sft/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =        2.0\n","  total_flos               =    47747GF\n","  train_loss               =     0.7742\n","  train_runtime            = 0:00:22.51\n","  train_samples_per_second =      0.666\n","  train_steps_per_second   =      0.133\n","06/01/2024 14:10:43 - WARNING - llamafactory.extras.ploting - No metric loss to plot.\n","06/01/2024 14:10:43 - WARNING - llamafactory.extras.ploting - No metric eval_loss to plot.\n","[INFO|trainer.py:3719] 2024-06-01 14:10:43,058 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3721] 2024-06-01 14:10:43,058 >>   Num examples = 1\n","[INFO|trainer.py:3724] 2024-06-01 14:10:43,059 >>   Batch size = 1\n","100% 1/1 [00:00<00:00, 248.45it/s]\n","***** eval metrics *****\n","  epoch                   =        2.0\n","  eval_loss               =     2.6887\n","  eval_runtime            = 0:00:00.99\n","  eval_samples_per_second =      1.004\n","  eval_steps_per_second   =      1.004\n","[INFO|modelcard.py:450] 2024-06-01 14:10:44,060 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 llamafactory-cli train examples/lora_single_gpu/llava1_5_lora_sft.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VzB9srXllk8A","outputId":"bed3af64-9e16-41a2-a25e-717adcb588d4","colab":{"referenced_widgets":["05e71b26d77d4ed2ad46c1aeee037015"]}},"outputs":[{"name":"stderr","output_type":"stream","text":["/root/anaconda3/envs/huggingface/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05e71b26d77d4ed2ad46c1aeee037015","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["合并后的模型已保存到 saves/llava1_5-7b/lora/merge\n"]}],"source":["import torch\n","from transformers import LlavaForConditionalGeneration, AutoTokenizer\n","from peft import PeftModel, PeftConfig\n","\n","# 加载基础模型\n","base_model_name = \"llava-hf/llava-1.5-7b-hf\"\n","base_model = LlavaForConditionalGeneration.from_pretrained(\n","    base_model_name,\n","    torch_dtype=torch.float16,\n","    low_cpu_mem_usage=True,\n",").to(0)\n","tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n","\n","# 加载LoRA微调的配置\n","lora_model_dir = \"saves/llava1_5-7b/lora/sft\"\n","peft_config = PeftConfig.from_pretrained(lora_model_dir)\n","\n","# 加载LoRA微调模型\n","lora_model = PeftModel.from_pretrained(base_model, lora_model_dir)\n","\n","# 合并基础模型和LoRA权重\n","merged_model = lora_model.merge_and_unload()\n","\n","# 保存合并后的模型\n","merged_model_dir = \"saves/llava1_5-7b/lora/merge\"\n","merged_model.save_pretrained(merged_model_dir)\n","tokenizer.save_pretrained(merged_model_dir)\n","\n","print(f\"合并后的模型已保存到 {merged_model_dir}\")"]},{"cell_type":"markdown","metadata":{"id":"-n_ecZKxlk8B"},"source":["## 验证一下"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bvCAQl3flk8B"},"outputs":[],"source":["import requests\n","from PIL import Image\n","\n","import torch\n","from transformers import AutoProcessor, LlavaForConditionalGeneration\n","\n","model_id = \"/root/LLaMA-Factory/saves/llava1_5-7b/lora/merge/\"\n","\n","prompt = \"USER: <image>\\nPlease describe this image\\nASSISTANT:\"\n","image_file = \"/root/LLaMA-Factory/data/mllm_demo_data/3.jpg\"\n","\n","model = LlavaForConditionalGeneration.from_pretrained(\n","    pretrained_model_name_or_path=model_id,\n","    cache_dir=model_id,\n","    torch_dtype=torch.float16,\n","    low_cpu_mem_usage=True,\n",").to(0)\n","\n","processor = AutoProcessor.from_pretrained(model_id)\n","\n","\n","raw_image = Image.open(image_file)\n","inputs = processor(prompt, raw_image, return_tensors='pt').to(0, torch.float16)\n","\n","output = model.generate(**inputs, max_new_tokens=200, do_sample=False)\n","print(processor.decode(output[0][2:], skip_special_tokens=True))"]},{"cell_type":"markdown","source":["## Convert Pytorch Model to Quantize GGUF to Run on Ollama"],"metadata":{"id":"IALNiFJfloF2"}},{"cell_type":"code","source":["# cp -r [hugginface saved path] [new easy to remember path]/bonito\n","\n","# Import a model\n","# git clone https://github.com/ollama/ollama.git\n","# cd ollama\n","# git submodule init\n","# git submodule update llm/llama.cpp\n","# python3 -m venv llm/llama.cpp/.venv\n","# source llm/llama.cpp/.venv/bin/activate\n","# pip install -r llm/llama.cpp/requirements.txt\n","# make -C llm/llama.cpp quantize\n","\n","# python llm/llama.cpp/convert.py --vocab-type bpe \\\n","#                                 ./model/Llama3-8B-Huatuo-SFT \\\n","#                                 --outtype f16 \\\n","#                                 --outfile ./model/llama3-8b-huatuo-sft-f16.bin\n","# llm/llama.cpp/quantize ./model/llama3-8b-huatuo-sft-f16.bin ./model/llama3-8b-huatuo-sft-q4.bin q4_0\n","# ollama create llama3-8b-huatuo-sft -f ./model/llama3-8b-huatuo-sft-q4.Modelfile\n","\n","\n","git clone https://github.com/ollama/ollama.git\n","cd ollama\n","git submodule init\n","git submodule update llm/llama.cpp\n","pip install -r llm/llama.cpp/requirements.txt\n","\n","\n","# python llama.cpp/convert.py bonito\n","\n","# cd llama.cpp\n","# make\n","# ./quantize [your path to]/bonito/ggml-model-f32.gguf [your path to]/bonito/ggml-model-f32.gguf-Q4_K_M.gguf Q4_K_M"],"metadata":{"id":"YUK0W5VOlrAQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CSqAmvqf4wFJ"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"colab":{"provenance":[{"file_id":"https://github.com/changz1115/multimodal/blob/main/jypyter/colab/colab_fine_tuning_llava15_mllm_demo.ipynb","timestamp":1716772116949}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}